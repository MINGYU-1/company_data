# 2025 기업데이터 활용 AI 경진대회

> 🔗 **관련 공지사항:** https://sducoss.ac.kr/ko/community/notice/inno/view/169?p=1


---

## 2. 🗓️ 전체 프로젝트 일정 (Timeline)
| 주차 (Week) | 기간 (Date) | 핵심 목표 (Key Objective) |
| :--- | :--- | :--- |
| **1주차** | 11/10 ~ 11/16 | **'무엇을' 풀 것인가?** (도메인 확정) |
| **2주차** | 11/17 ~ 11/23 | **'왜' 이 데이터인가?** (EDA 및 근거 확보) |
| **3주차** | 11/24 ~ 11/30 | **'어떻게' 성능을 높일 것인가?** (모델 반복 개선) |
| **4주차** | ~ 12/3 | **'어떻게' 포장할 것인가?** (제안서 및 제출) |

---

## 3. 👨‍💻 주차별 상세 계획 (Detailed Weekly Plan)

### 1️⃣ 주차: '무엇을' 풀 것인가? (도메인 확정)
* **핵심 목표:** 팀원 전체가 '무엇을 풀 것인지'에 대해 명확히 합의합니다.
* **Action Items:**
    1.  해결하려는 **'소상공인의 문제'** 구체적으로 정의 (예: "신규 창업자의 초기 6개월 매출 예측")
    2.  문제를 해결하기 위해 사용할 **핵심 데이터 세트 목록** 선정 (예: 중소기업빅데이터 A, 공공데이터 B)
    3.  Git 저장소 개설 및 기본 폴더 구조 세팅 
### 2️⃣ 주차: '왜' 이 데이터인가? (EDA 및 근거 확보)
* **핵심 목표:** 데이터를 깊이 있게 탐색하고, 1주 차에 선정한 '문제'와 '데이터'가 논리적으로 연결되는 근거를 찾습니다.
* **Action Items:**
    1.  (개인 작업) EDA 코드 작성 및 Git에 Push 
    2.  (팀 회의) Pull Request(PR) 화면을 보며 토론
        * "이 변수에서 이런 인사이트가 나왔습니다."
        * "결측치/이상치 처리 방안"
        * "A와 B 변수를 조합하여 C라는 새로운 의미(파생변수)를 찾았습니다."

### 3️⃣ 주차: '어떻게' 성능을 높일 것인가? (모델 반복 개선)
* **핵심 목표:** '어떻게 예측 성능을 높일 것인가'에 집중하며, 모델을 반복적으로 개선합니다.
* **Action Items:**
    1.  **베이스라인 모델** 수립 (예: Logistic Regression, 기본 LightGBM)
    2.  (개인 작업) Git 브랜치 생성 후 모델 성능 개선 작업 수행
        * **특성 엔지니어링 (Feature Engineering):** EDA 기반 파생 변수 생성
        * **모델 변경:** RandomForest, XGBoost 등 다양한 알고리즘 테스트
        * **하이퍼파라미터 튜닝**
    3.  (팀 회의) 성능 향상에 기여한/실패한 시도 리뷰 및 최종 모델 방향성 확정

### 4️⃣ 주차: '어떻게' 포장할 것인가? (제안서 및 제출)
* **핵심 목표:** 3주 차까지 만든 최종 모델과 2주 차에 찾은 논리적 근거(EDA)를 바탕으로, 심사위원을 설득할 수 있는 최종 제안서를 완성합니다.
* **Action Items:**
    1.  **제안서 작성:** (아래 4번 항목 '제안서 작성 가이드' 참고)
    2.  모델 성능만 나열하는 것이 아니라, 2주 차의 근거(EDA)를 통해 "왜" 이 모델이 타당한지 설득력 있게 전달
    3.  `main` 브랜치의 코드 최종 정리 (주석, 변수명 등)
    4.  최종 제안서 및 코드 제출 (12/3)

---

## 📅 11월 9일: 프로젝트 기획 및 데이터 수집

* **프로젝트 기획**: 소상공인(SME) 데이터를 활용한 분석 아이디어를 구상하고, 분석할 업종을 선정
* **Git 학습**: Git의 `merge` 기능 사용법을 확인
* **데이터 수집 스크립트 작성**: Wehago API(`data.go.kr`)에서 데이터를 대량 수집하는 Python 스크립트를 작성
    * `requests`와 `dotenv`를 사용해 API 키를 관리
    * `DATASET_SUNDO_69` (숙박업) 데이터를 500개 단위로 반복 조회하여 전체를 가져오는 로직을 구현
    * 수집한 데이터를 `data_csv/숙박업_강원도_읍면동.csv` 파일로 저장s

---

## 📅 11월 10일: 원본 데이터 탐색(EDA) 및 요식업소 좌표 변환

이날은 분석에 필요한 다양한 원본 CSV 파일들을 `pandas`로 불러와 기본적인 탐색(EDA)을 수행했습니다.

* **춘천시 버스 노선 탐색** (`11_10_강원도버스노선.ipynb`):
    * `춘천시_버스정류장노선정보_20250212.csv` (15,780행)를 로드했습니다.
    * `value_counts()`로 '노선번호'를 확인하여 총 222개의 고유 노선이 있음을 파악했습니다.

* **춘천시 모범 음식점 탐색** (`11_10_모범음식점.ipynb`):
    * `강원도_모범음식점.csv`를 로드하고 '시군구' 컬럼이 '춘천시'인 데이터를 필터링하여 총 107개소가 있음을 확인했습니다.

* **강원도 숙박업 탐색** (`11_10_숙박업분석.ipynb`):
    * 11월 9일에 수집한 `숙박업_강원도_읍면동.csv` 파일을 로드했습니다.
    * '연봉', '온라인 거래 유무' 등의 컬럼을 `value_counts()`로 탐색했습니다.

* **춘천시 요식업소 좌표 변환** (`11_10_소재지변경.ipynb`):
    * `춘천시_요식업소현황_2504.csv` (6,272행)의 '소재지(도로명)' 주소를 **Kakao API**를 이용해 위도/경도 좌표로 변환했습니다.
    * 좌표가 추가된 데이터를 `춘천시_요식업소_좌표포함.csv`로 저장했습니다.

---

## 📅 11월 11일: 핵심 분석 (업종-버스정류장 100m 공간 조인)

이날은 프로젝트의 핵심 분석인 '업소-버스정류장 간 근접성'을 계산했습니다.

* **강원도 인구 데이터 탐색** (`11_11_강원도주민등록인구및세대.ipynb`):
    * `주민등록인구및세대.csv`를 로드하고 `info()`로 데이터 구조를 확인했습니다.

* **분석 대상 업종 선정 및 좌표 변환** (`11_11_강원업종.ipynb`):
    1.  `강원도업종.csv` (356행)를 로드했습니다.
    2.  '주소' 컬럼에서 '춘천시'만 필터링하여 `춘천시업종.csv` (34행)를 생성했습니다.
    3.  이 34개 업소의 주소를 **Kakao API**로 좌표 변환하여 `춘천시업종_좌표포함.csv`로 저장했습니다.

* **공간 조인 (Spatial Join)** (`11_11_춘천시업종버스.ipynb`):
    1.  `춘천시업종_좌표포함.csv` (업소 34개)와 `춘천시_버스정류장노선정보_20250212.csv` (정류장 15,780개)를 로드했습니다.
    2.  `geopandas`를 사용해 두 데이터를 `GeoDataFrame`으로 변환했습니다.
    3.  정확한 거리 계산을 위해 좌표계(CRS)를 `EPSG:5186` (미터 단위)으로 통일했습니다.
    4.  `gpd.sjoin_nearest`를 실행하여 각 업소 기준 **100m 이내(`max_distance=100`)**에 있는 버스정류장을 찾아 병합했습니다.
    5.  최종 결과물인 `업종_100m이내_버스정류장_목록.csv` (22건의 연결)를 저장했습니다.

---

## 📅 11월 12일: 분석 결과 확인

* **결과 검토** (`11_12_업종이랑 버스정류장 merge.ipynb`):
    * 11월 11일에 생성한 최종 결과물 `업종_100m이내_버스정류장_목록.csv` (22행)을 `pandas`로 다시 불러와 내용을 검토했습니다.

---

## 📅 11월 13일: CSV to SQL 변환

* **데이터베이스 적재 준비** (SQL 스크립트 3개 생성):
    * 분석에 사용된 주요 CSV 파일들을 MySQL DB에 `INSERT`할 수 있도록 `CREATE TABLE`문과 `INSERT INTO`문이 포함된 `.sql` 파일 3개를 생성했습니다.
    1.  `강원도업종.csv` -> `insert_kangwondo_businesses.sql`
    2.  `춘천시업종_좌표포함.csv` -> `insert_chuncheon_businesses_with_coords.sql`
    3.  `업종_100m이내_버스정류장_목록.csv` -> `insert_business_near_stops.sql`

---

## 📅 11월 14일: 데이터베이스(DB) 연결 및 테이블 확인

* **DB 연결 및 확인** (`11_14_connecting_db.ipynb`):
    * `mysql.connector`와 `dotenv`를 사용해 로컬 MySQL 서버(`127.0.0.1`)의 `new_schema` 데이터베이스에 연결했습니다.
    * `SHOW TABLES` 쿼리를 실행하여 11월 13일에 생성한 SQL 스크립트가 잘 적용되었는지 확인했습니다.
    * **확인된 테이블**: `kangwondo_businesses`와 `chuncheon_businesses_with_coords` 등이 `new_schema`에 존재하는 것을 확인했습니다.